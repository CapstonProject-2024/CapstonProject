- **continual learning**
    
    ; refers to training on a series of multiple tasks or incremental classes
    
    새로운 데이터를 지속적으로 학습하여 모델의 능력을 개선하는 것
    
    - 기존의 머신 러닝 모델은 새로운 데이터를 받아들일 때마다 처음부터 다시 학습해야 했기 때문에, 새로운 데이터를 수집하는데는 많은 시간과 비용이 필요했다. 또한, 새로운 데이터를 받아들일 때만 모델의 성능이 향상되지 않았기 때문에, 모델의 성능 개선에 한계가 있었다.
        
        ![스크린샷 2024-09-27 오전 2.36.40.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/23df5ce0-5f81-4517-92db-4136c580b257/1e51c73c-3a81-4d26-957d-fa21d1a9b312/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2024-09-27_%E1%84%8B%E1%85%A9%E1%84%8C%E1%85%A5%E1%86%AB_2.36.40.png)
        
        continula learning은 이러한 한계를 극복하기 위해 제안된 방법으로, 기존의 모델을 재사용하고, 새로운 데이터를 추가로 학습하여 모델의 성능을 개선한다.
        
        이를 위해, 기존의 데이터와 새로운 데이터를 적절하게 조합하여 학습 데이터를 구성하고, 학습된 모델의 파라미터를 초기값으로 사용하여 새로운 데이터를 학습한다. 이러한 방식으로 모델이 새로운 데이터를 수용하고 적응하면서, 모델의 성능을 개선할 수 있다. 
        
        continula learning은 현실적인 문제를 해결하기 위해 필수적인 방법이 될 수 있다. 예를 들어, 의료 분야에서 새로운 환자 데이터를 지속적으로 수집하면서 의료 진단에 대한 모델의 성능을 개선할 수 있다. 또한 자율 주행 자동차와 같이 학습 데이터가 지속적으로 증가하면서 모델을 업데이트 하는데 사용될 수 있다.
        
        몇 가지 보완점 및 해결해야 할 점
        
        - catastrophic forgetting
            
            새로운 데이터를 계속해서 추가하고 모델을 업데이트 하기 때문에, 이전 데이터와 새로운 데이터 간의 충돌이 발생할 수 있다. 이전에 학습된 데이터를 까먹고 새로운 데이터에 적응하는 현상을 catastrophic forgetting라고 한다.
            
            모델이 이전 데이터를 기억할 수 있도록 하는 방법이 필요
            
        - 데이터 분포의 변화
            
            데이터 분포가 지속적으로 변화하므로, 이전에 학습한 데이터 분포와 새로운 데이터 분포 간에 차이가 발생할 수 있다. 
            
            모델이 데이터 분포 변화를 인식하고, 이를 적절하게 처리할 수 있는 방법이 필요
            
        - 학습 시간 증가
            
            지속적으로 학습해야 하므로 학습시간이 늘어남.
            
            효율적인 학습 방법이 필요
            
        - 레이블링 비용
            
            새로운 데이터를 지속적으로 수집하고 레이블링해야 하므로, 레이블링 비용이 증가할 수 있다.
            
            레이블링 비용을 줄일 수 있는 방법이 필요
            
    
    - 상황: Machine Learning을 5G/6G 통신이나 Image Processing 등 여러 Domain에 적용하는 사례가 늘어나고 있다. 하지만, 단순히 AI를 적용했다의 의미를 넘어서, 실용성이 있기 위해서 넘어야 하는 허들이 몇 가지 있다.  그 중 한 가지가, 바뀌는 환경에 잘 적응을 해야한다는 점이다. 바뀌는 환경에 빠르게 적응하지 못하는 AI 모델은 사용자 입장에서 불안해서 사용할 수 없을 것이다. 이런 문제점을 극복하기 위해, Inference 이후에도, 계속 주어진 Dataset으로 Train을 하는 Online-Learning, 주어진 환경에 맞게 Fine Tuning하는 Transfer Learning 등 다양한 Approach 등이 있다. 이번 글에서는 그 중에, Transfer Learning의 문제점을 보완하는 Continual Learning에 대해 정리해보려고 한다.
    
    https://junia3.github.io/blog/continual
    
    https://engineering-ladder.tistory.com/94
    
    https://blog.naver.com/totalcmd/223080719433
    

- 주요 목적

forgetting problem(where previously learned knowledge is decaying over time as adapting to new tasks)을 memorization [40, 52] 또는 regularization을 사용해서 다루는 것이다.



---

**Knowledge-reusable continual learning**

- 모델에 연결하여, 입력 데이터를 이전 모델을 통해 전파시키는 방식에 초점을 맞추고 있습니다.
- 후속 작업들에 대해 기존 지식의 재사용하는 것에 대한 흥미가 증가하고 있다.
    
    ;새로운 모델을 이전 모델에 연결하여, 입력 데이터를 이전 모델을 통해 전파시키는 방식에 초점
    
- 전체 지식을 재사용하는 것이 아닌, 모델의 필요한 부분만 활성화시키는 것을 제안한다.
- 출력의 이질성에 대한 유연성을 제공하여, 대부분의 클라이언트가 다른 출력 형태를 가지고 있는 현실 세계의 시나리오에서 더 넓은 적용 가능성을 보장
    
    ↔ 일부 연구는 코사인 유사도와 같은 유사성 측정값을 연합 학습 시나리오에 적용했지만, 이는 서로 다른 출력(클래스) 수를 가진 클라이언트에 적용할 때 한계
    
    **Knowledge-reusable continual learning의 예시**
    
    - **piggyback**
        - 연구에서 공유 가능한 단일 모델을 사용하고, 불필요한 뉴런을 마스킹하여 특정 작업에 필요한 지식을 추출한다.
        - 기존 지식을 효과적으로 재사용할 수 있지만, **점진적인 작업**을 처리하는 데에는 한계가 있다.
    - **CPG**
        - 뉴런 확장과 뉴런 가지치기 및 마스킹 기법을 결합하여 망각 문제, 모델 압축성, 그리고 지식 재사용의 높은 정확도 문제를 해결한다.
    - **decision pattern-based similarity**
        - 연합 지속 학습에서 새로운 접근 방식
        - 지식 자체가 비슷한 결정 패턴을 가지고 있어도 정확히 동일하지는 않다.
            
             이를 통해 개인 학습자는 유사하지만 보지 못했던 더 광범위한 지식에 노출되며, 후속 학습 작업에서 성능과 효율성이 향상됩니다.
            


---

---

- 엣지 AI의 광범위한 접근 가능성으로 인해, 학습자들은 자신의 개인 지식에만 국한되지 않는다.
    
    → 독립적인 학습자는 자신의 로컬 정보에만 접근할 수 있도록 허용되며, 이로 인해 경험이 제한될 수 있다.
    
- task-incremental learning (↔ 최근 연구들은 class-incremental learning에 초점)
    - 전이 학습이 매우 효과적
    
    - 과정
    1. 모델이 출발 도메인에서 사전 훈련(pretrained)
    2. 목표 도메인(target domain)에 맞게 미세 조정(finetuned)
    - 선택적 장치 간 지식 전이는 모델 충실도(model fidelity)를 높이는 중요한 촉매제가 될 수 있다.
        
        → 연합 지속 학습 분야에서 일반적으로 다루어지고 있지만, 중앙 집중식 방식에서만 이루어지고 있다.
        

- 중앙 집중식 방식의 한계
    
    ⇒ FedWeIT
    
    : 클라이언트에서 파라미터를 집계하여 global knowledge로 만든 다음, 클라이언트가 특정 작업에 적응하도록 연합 파라미터를 마스킹
    
    - 중앙 서버에 의존하여 통신 병목 현상 및 프라이버시 한계를 초래
    - 사전 학습된 모델의 한계
- 사전 학습된 모델의 한계
    
    ⇒ mageNet
    
    : 사전 훈련된 모델은 전이 학습에서 널리 활용되지만, 이는 엣지 측의 연합 지속 학습에 적합하지 않다.
    
    - 사전 훈련된 모델은 잘 알려진 대규모 아키텍처를 위해 설계되었기 때문입니다.
    - 지속 학습에서의 아키텍처는 동적으로 변화하며, 엣지 AI는 대규모 모델에 맞게 조정될 수 없습니다.

- 그러나!
Pick-a-back, we rather explore decentralized, communication-efficient, and
privacy-preserving knowledge transfer in lightweight on-device models.

- Class-Incremental Learning 방식은 여러 Task를 순서대로 학습한 뒤, 모든 Task의 클래스에 대한 시험을 한 번에 보는 방식입니다.
    
    반면 Task-Incremental Learning 방식은 똑같이 여러 Task를 순서대로 학습한 뒤, 시험을 볼 때는 이건 어떤 Task에서 학습한 문제라는 걸 알려준 뒤 Class를 맞추도록 시험을 보는 방식입니다.
    
    참고) https://ffighting.net/deep-learning-paper-review/incremental-learning/all-about-incremental-learning/#3_ClassTask_Incremental_Learning
    

\
